---
commentable: true
abstract: 研讨会涵盖了多个主题，包括利用生成模型填充时间序列数据中的缺失值，采用注意力机制进行视频摘要和推荐，以及一种新颖的基于Swin Transformer优化算法等。
address:
  city: 悉尼
  country: 澳大利亚
  postcode: "2006"
all_day: false
authors: []
date: "2023-05-26T18:00:00Z"
date_end: "2023-05-26T20:00:00Z"
event: 深度学习研讨会
featured: false
image:
  caption: 'Image credit: [**SCSLab**](http://scslab.net/)'
  focal_point: Right
location: 悉尼大学
math: true
publishDate: "2023-01-01T00:00:00Z"
summary: 参加深度学习研讨会，与深度学习研究方向同僚进行深入交流，探索尖端的深度学习技术，并与项目导师[**徐畅教授**](http://changxu.xyz/)合影留念。
tags: []
title: 深度学习研讨会
---
研讨会具体涵盖以下主题：

- 利用生成模型填充时间序列数据中的缺失值：该主题探讨了将生成模型（如自编码器或变分自编码器）应用于填补时间序列数据中的间隙或缺失值。这些模型经过训练，学习数据中的潜在模式和依赖关系，从而能够为缺失的数据条目生成合理的值。

- 采用注意力机制进行视频摘要和推荐：该主题专注于使用注意力机制，这是深度学习模型的关键组成部分，以改善视频摘要和推荐系统。注意力机制使模型能够关注重要的视频片段或帧，捕捉最相关的信息，用于摘要和个性化推荐。

- Swin Transformer的一种新型优化思路：Swin Transformer是计算机视觉领域的一项新进展，以其高效处理具有大感受野的图像数据而闻名。该主题介绍了一种专门为Swin Transformer设计的新型优化思路，旨在提升其在图像分类或目标检测等任务中的性能。这种方法涉及架构修改、训练技术以及为Swin Transformer量身定制的算法优化。

以上仅是研讨会涵盖的几个主题，为与会者提供了有关深度学习领域最新进展和技术的深入洞察。
